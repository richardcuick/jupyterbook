{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d860e98-9969-4e71-b791-e35620e327fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/23/98/c70fac0f1b3193ced86013b563119c27c68ac26b684815f407555224108d/langchain-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (3.9.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/ae/53/8c006de775834cd4ea64a445402dc195caeebb77dc76b7defb9b3887cb0d/dataclasses_json-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.9 (from langchain)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.9 from https://files.pythonhosted.org/packages/3b/db/ce4a9244a6a2d9fc07394f94fe4c7041a478cc14e03072f9e8bbece92667/langchain_community-0.0.10-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.7 from https://files.pythonhosted.org/packages/02/0c/a2c7cee72c36f3fe01769681332434cdaaef5818865d7cf78a122716d7b3/langchain_core-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.77 from https://files.pythonhosted.org/packages/f4/19/cd0fb165ac8262eaca59bd7a5991085fac97eb748a04749681bef92a5281/langsmith-0.0.78-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.78-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/798.0 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --- ----------------------------------- 71.7/798.0 kB 206.9 kB/s eta 0:00:04\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 194.6/798.0 kB 294.9 kB/s eta 0:00:03\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.0 kB 426.2 kB/s eta 0:00:01\n",
      "   -------------------------------------  788.5/798.0 kB 607.5 kB/s eta 0:00:01\n",
      "   -------------------------------------  788.5/798.0 kB 607.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 798.0/798.0 kB 579.6 kB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.10-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.8-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 215.5/215.5 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.78-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.4/48.4 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 502.5 kB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   -------------------------------------- - 51.2/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 548.3 kB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain-community, langchain\n",
      "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 langchain-0.1.0 langchain-community-0.0.10 langchain-core-0.1.8 langsmith-0.0.78 marshmallow-3.20.1 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script langsmith.exe is installed in 'C:\\Users\\richa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'C:\\Users\\richa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fce6c35-b0a8-479e-8cb6-1448c42e7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set LANGCHAIN_TRACING_V2=\"true\"\n",
    "!set LANGCHAIN_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d6c6c8-224f-4b82-91c4-5e69d41dc894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_openai\n",
      "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/f4/ba/6cfe8bdcc0c4f6b420d9f6128d1970273764eb1a7c2e3ef02efa2271dd30/langchain_openai-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\richa\\appdata\\roaming\\python\\python311\\site-packages (from langchain_openai) (0.1.8)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_openai) (1.26.2)\n",
      "Collecting openai<2.0.0,>=1.6.1 (from langchain_openai)\n",
      "  Obtaining dependency information for openai<2.0.0,>=1.6.1 from https://files.pythonhosted.org/packages/2a/70/5ff7a2c5b37f6cab5ed3df59539d80d959e210d1127dea8e3de14897c4f3/openai-1.7.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain_openai)\n",
      "  Obtaining dependency information for tiktoken<0.6.0,>=0.5.2 from https://files.pythonhosted.org/packages/f1/62/73629527ff413c8ce20189d29eb52a91d6d4571e3214ef6d5a2c00ca4081/tiktoken-0.5.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\richa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\richa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (0.0.78)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\richa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.6.1->langchain_openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.3 kB ? eta -:--:--\n",
      "     --------------------------------- ---- 51.2/58.3 kB 130.9 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 51.2/58.3 kB 130.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 58.3/58.3 kB 133.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain_openai) (2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain_openai) (1.26.18)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.6.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.0.2-py3-none-any.whl (28 kB)\n",
      "Downloading openai-1.7.0-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/224.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/224.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/224.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/224.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/224.7 kB ? eta -:--:--\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 153.6/224.7 kB 458.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 215.0/224.7 kB 335.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 224.7/224.7 kB 311.8 kB/s eta 0:00:00\n",
      "Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 204.8/786.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 204.8/786.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 204.8/786.4 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 204.8/786.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 276.5/786.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 786.4/786.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB 855.2 kB/s eta 0:00:00\n",
      "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain_openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 langchain_openai-0.0.2 openai-1.7.0 tiktoken-0.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\richa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'C:\\Users\\richa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df700c46-7948-4836-8baf-9a5664759323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=\"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\"\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c788fb5c-d899-4ab6-bd6d-87b6af3a36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8283054d-69fa-42cf-984c-b1f4aa6bbc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in the following ways:\\n\\n1. Test Automation: Langsmith can generate test scripts automatically, allowing for faster and more efficient testing. It can generate a variety of test scenarios and data inputs to cover a wide range of test cases.\\n\\n2. Test Data Generation: Langsmith can generate realistic and diverse test data that covers different input combinations, edge cases, and boundary conditions. This helps in validating the behavior and performance of the system under different scenarios.\\n\\n3. Test Case Generation: Langsmith can automatically generate test cases based on predefined specifications or requirements. It can identify potential test scenarios and generate test cases to cover those scenarios, reducing the manual effort required for test case creation.\\n\\n4. Test Oracles: Langsmith can provide support for defining expected outcomes and validating actual outcomes. It can analyze the system's behavior and generate oracles that can be used to verify the correctness of the test results.\\n\\n5. Test Optimization: Langsmith can optimize the test suite by identifying redundant or overlapping test cases. It can prioritize test cases based on their relevance, coverage, and importance, allowing for efficient test execution.\\n\\n6. Test Maintenance: Langsmith can assist in maintaining test cases and test data by automatically updating them when changes occur in the system under test. It can analyze the impact of changes and update the test artifacts accordingly, reducing the effort required for test maintenance.\\n\\nOverall, Langsmith helps streamline the testing process, reduces manual effort, improves test coverage, and enhances the quality and reliability of the testing outcomes.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0679253-0232-4d34-819d-7239637f3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa4cf7e-975e-496c-9403-bd87b7522982",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb1e77d6-a2b2-4914-b0ae-2940f9351e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can be a valuable tool in the testing process by providing automated language testing capabilities. Here are a few ways in which Langsmith can help with testing:\\n\\n1. Language Validation: Langsmith can check if the language used in a software application or website is accurate and follows the specified guidelines. It can identify spelling errors, grammar mistakes, inconsistencies, and incorrect terminology, ensuring that the language used meets the desired standards.\\n\\n2. Localization Testing: Langsmith can assist with localization testing by verifying the accuracy of translations. It can compare the source language with the translated version to identify any discrepancies, missing translations, or cultural appropriateness issues. This helps ensure that the software or website functions correctly in different languages and cultures.\\n\\n3. User Interface Testing: Langsmith can help test the language used in the user interface of an application or website. It can validate the text displayed in menus, buttons, error messages, tooltips, and other UI elements. This ensures that the language is clear, concise, and consistent, enhancing the overall user experience.\\n\\n4. Content Testing: Langsmith can analyze and test the content of documentation, user manuals, knowledge bases, and other textual resources. It can identify any inconsistencies, outdated information, or unclear instructions, helping to improve the quality and accuracy of the content.\\n\\n5. Compliance Testing: Langsmith can assist with compliance testing by ensuring that the language used in legal disclaimers, privacy policies, terms of service, and other compliance-related documents meets the required standards. It can identify any language that might be misleading, non-compliant, or contradictory, reducing legal risks.\\n\\n6. Accessibility Testing: Langsmith can help test the accessibility of software applications and websites by analyzing the language used in alternative text for images, labels for form fields, and other accessibility-related elements. It can ensure that the language is descriptive and helpful for users with disabilities.\\n\\nOverall, Langsmith's language testing capabilities can contribute to a more robust and reliable testing process, improving the quality of software applications, websites, and documentation.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c487f3-7878-4d2d-bfda-5d81c9bd6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832b0d36-46f6-4e1a-8095-4998af2b8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43cd2d1-c746-4213-a66f-b133b2eb70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith can be a valuable tool for testing in several ways:\\n\\n1. Test Case Generation: Langsmith can automatically generate test cases based on the specifications provided. It can take inputs such as available resources, system constraints, and expected outputs to create comprehensive test cases that cover various scenarios. This helps in ensuring thorough test coverage.\\n\\n2. Test Data Generation: Langsmith can generate test data for different input parameters, helping to simulate real-world scenarios. It can create a wide range of data sets, including edge cases, invalid inputs, and boundary values. This aids in identifying potential issues and verifying the system's behavior in different scenarios.\\n\\n3. Test Environment Setup: Langsmith can assist in setting up the test environment by automatically configuring the necessary software, dependencies, and resources required for testing. It can streamline the environment setup process, saving time and effort for testers.\\n\\n4. Test Automation: Langsmith can generate automation scripts to execute test cases automatically. It can integrate with popular testing frameworks and tools, such as Selenium or JUnit, to run tests efficiently. This can significantly reduce manual effort and improve test execution speed.\\n\\n5. Test Documentation: Langsmith can generate detailed test documentation, including test plans, test cases, and test reports. It can automatically update documentation whenever changes are made to the system or test cases, ensuring that the documentation is always up to date.\\n\\nBy leveraging Langsmith's capabilities, testing teams can improve test coverage, generate realistic test data, automate repetitive tasks, streamline test environment setup, and maintain accurate test documentation. This ultimately leads to more efficient and effective testing processes.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91b4724-f94d-4b38-bbf9-a43daba07559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779f59cf-9256-43a6-975f-8e0bb0e93fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6737b171-2aff-453f-9702-e549c758adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     ---------------------------------------- 0.0/10.8 MB 87.1 kB/s eta 0:02:04\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "     --------------------------------------- 0.1/10.8 MB 112.3 kB/s eta 0:01:36\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.2/10.8 MB 214.3 kB/s eta 0:00:50\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     - ------------------------------------- 0.4/10.8 MB 336.2 kB/s eta 0:00:31\n",
      "     -- ------------------------------------ 0.6/10.8 MB 365.5 kB/s eta 0:00:28\n",
      "     --- ----------------------------------- 0.9/10.8 MB 554.8 kB/s eta 0:00:18\n",
      "     --- ----------------------------------- 0.9/10.8 MB 554.8 kB/s eta 0:00:18\n",
      "     --- ----------------------------------- 0.9/10.8 MB 554.8 kB/s eta 0:00:18\n",
      "     --- ----------------------------------- 0.9/10.8 MB 554.8 kB/s eta 0:00:18\n",
      "     --- ----------------------------------- 0.9/10.8 MB 554.8 kB/s eta 0:00:18\n",
      "     --- ----------------------------------- 0.9/10.8 MB 507.2 kB/s eta 0:00:20\n",
      "     ---- ---------------------------------- 1.3/10.8 MB 693.6 kB/s eta 0:00:14\n",
      "     ------ -------------------------------- 1.7/10.8 MB 907.5 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.7/10.8 MB 907.5 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.7/10.8 MB 907.5 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.7/10.8 MB 907.5 kB/s eta 0:00:10\n",
      "     ------ -------------------------------- 1.9/10.8 MB 904.7 kB/s eta 0:00:10\n",
      "     --------- ------------------------------ 2.4/10.8 MB 1.1 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 2.8/10.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 2.8/10.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 2.8/10.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 2.8/10.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 2.8/10.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ----------- ---------------------------- 3.1/10.8 MB 1.3 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 3.9/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.6 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 4.1/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "     ------------------ --------------------- 5.1/10.8 MB 1.8 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 6.2/10.8 MB 2.1 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 7.3/10.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.7/10.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.8/10.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.8/10.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 7.8/10.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 7.8/10.8 MB 2.4 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 9.2/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.8/10.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.1/10.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.8/10.8 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.8/10.8 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30bf5b48-7fbd-483f-9b85-04e8a7899d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: \"sk-ato2*****************************************VYY\". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter()\n\u001b[0;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n\u001b[1;32m----> 6\u001b[0m vector \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents, embeddings)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\vectorstores.py:508\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    507\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\vectorstores\\faiss.py:913\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    894\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 913\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m    915\u001b[0m         texts,\n\u001b[0;32m    916\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    921\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_openai\\embeddings\\base.py:482\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    481\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(texts, engine\u001b[38;5;241m=\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_openai\\embeddings\\base.py:325\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    323\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 325\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params\n\u001b[0;32m    327\u001b[0m     )\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    329\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\resources\\embeddings.py:103\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     97\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m     98\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    105\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    106\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    107\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    108\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    109\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    110\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    111\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    112\u001b[0m     ),\n\u001b[0;32m    113\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    114\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1091\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1079\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1087\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1088\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1089\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1090\u001b[0m     )\n\u001b[1;32m-> 1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:852\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    845\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    851\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    853\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    854\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    855\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    856\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    857\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    858\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m    931\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    936\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    937\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    941\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: \"sk-ato2*****************************************VYY\". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63acc68f-1494-46ce-b2b1-4deaba8b7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a7f8a20-939d-4359-834c-b198c704854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing users to visualize test results.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e0a0cdf-8af1-4c87-beef-e35f1e8bcdde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n\u001b[1;32m----> 3\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m      4\u001b[0m retrieval_chain \u001b[38;5;241m=\u001b[39m create_retrieval_chain(retriever, document_chain)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "551805a2-2bca-4eb6-8762-4696fc01e881",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieval_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m retrieval_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow can langsmith help with testing?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retrieval_chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de092242-076a-4173-b94f-5860bbc0a8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
